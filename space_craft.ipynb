{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "space_craft.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elamathy-S/Coursera---Applied-data-science-with-python/blob/master/space_craft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkxgYWASDAGz"
      },
      "source": [
        "# Modified Squeezenet\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7XIFwbQ6qsb",
        "outputId": "512ffc7b-d895-4ec7-8340-fad3c7a64427"
      },
      "source": [
        "!pip install pipreqs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pipreqs\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/83/b1560948400a07ec094a15c2f64587b70e1a5ab5f7b375ba902fcab5b6c3/pipreqs-0.4.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from pipreqs) (0.6.2)\n",
            "Collecting yarg\n",
            "  Downloading https://files.pythonhosted.org/packages/8b/90/89a2ff242ccab6a24fbab18dbbabc67c51a6f0ed01f9a0f41689dc177419/yarg-0.1.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yarg->pipreqs) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2.10)\n",
            "Installing collected packages: yarg, pipreqs\n",
            "Successfully installed pipreqs-0.4.10 yarg-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYXGfM4O6uNV"
      },
      "source": [
        "!pip freeze -> requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyCQnnApDHyw",
        "outputId": "6e755e9d-e5a5-43b6-f3ef-4c96b1f21e1f"
      },
      "source": [
        "#fixed version of tqdm output for Colab\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n",
        "#IGNORE restart runtime warning, it is indeed installed\n",
        "#missing a few extra packages that we will need later! \n",
        "!pip install efficientnet_pytorch\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/chengs/tqdm/archive/colab.zip\n",
            "\u001b[?25l  Downloading https://github.com/chengs/tqdm/archive/colab.zip\n",
            "\u001b[K     - 256kB 10.4MB/s\n",
            "\u001b[?25hBuilding wheels for collected packages: tqdm\n",
            "  Building wheel for tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tqdm: filename=tqdm-4.28.1-py2.py3-none-any.whl size=47879 sha256=50c625b07b2c036d840e058c19fe76f47193817ef6ec46d785e58c86b3198c19\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qdl3ov_b/wheels/41/18/ee/d5dd158441b27965855b1bbae03fa2d8a91fe645c01b419896\n",
            "Successfully built tqdm\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed tqdm-4.28.1\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/a0/dd40b50aebf0028054b6b35062948da01123d7be38d08b6b1e5435df6363/efficientnet_pytorch-0.7.1.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-cp37-none-any.whl size=16443 sha256=4e6c13c0e20abb38ebc62af131b25ba3a27a85419b0ea7a2c1fd9a6f2ea5049e\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/27/aa/c46d23c4e8cc72d41283862b1437e0b3ad318417e8ed7d5921\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (57.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxKJa0ytbKcH",
        "outputId": "3759e9d1-7720-4e2f-a475-50eab6b2fe37"
      },
      "source": [
        "!git clone https://github.com/myproject-01/space.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'space'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 180 (delta 90), reused 180 (delta 90), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (180/180), 23.64 MiB | 7.56 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEv5mLz4hZNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed731b5-26e6-4b0e-d14a-9ee2571d7870"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knnFbw4d9qtd"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaDJldHu9cQ3"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pycocotools.coco import COCO\n",
        "import cv2\n",
        "\n",
        "\n",
        "class CocoDataset(Dataset):\n",
        "    def __init__(self, root_dir, img_dir=\"images\", set_dir='train2017', transform=None):\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.img_dir = img_dir\n",
        "        self.set_name = set_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.coco = COCO(os.path.join(self.root_dir, 'annotations', 'instances_' + self.set_name + '.json'))\n",
        "        self.image_ids = self.coco.getImgIds()\n",
        "\n",
        "        self.load_classes()\n",
        "\n",
        "    def load_classes(self):\n",
        "\n",
        "        # load class names (name -> label)\n",
        "        categories = self.coco.loadCats(self.coco.getCatIds())\n",
        "        categories.sort(key=lambda x: x['id'])\n",
        "\n",
        "        self.classes = {}\n",
        "        self.coco_labels = {}\n",
        "        self.coco_labels_inverse = {}\n",
        "        for c in categories:\n",
        "            self.coco_labels[len(self.classes)] = c['id']\n",
        "            self.coco_labels_inverse[c['id']] = len(self.classes)\n",
        "            self.classes[c['name']] = len(self.classes)\n",
        "\n",
        "        # also load the reverse (label -> name)\n",
        "        self.labels = {}\n",
        "        for key, value in self.classes.items():\n",
        "            self.labels[value] = key\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img = self.load_image(idx)\n",
        "        annot = self.load_annotations(idx)\n",
        "        sample = {'img': img, 'annot': annot}\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample\n",
        "\n",
        "    def load_image(self, image_index):\n",
        "        image_info = self.coco.loadImgs(self.image_ids[image_index])[0]\n",
        "        path = os.path.join(self.root_dir, self.img_dir, self.set_name, image_info['file_name'])\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # if len(img.shape) == 2:\n",
        "        #     img = skimage.color.gray2rgb(img)\n",
        "\n",
        "        return img.astype(np.float32) / 255.\n",
        "\n",
        "    def load_annotations(self, image_index):\n",
        "        # get ground truth annotations\n",
        "        annotations_ids = self.coco.getAnnIds(imgIds=self.image_ids[image_index], iscrowd=False)\n",
        "        annotations = np.zeros((0, 5))\n",
        "\n",
        "        # some images appear to miss annotations\n",
        "        if len(annotations_ids) == 0:\n",
        "            return annotations\n",
        "\n",
        "        # parse annotations\n",
        "        coco_annotations = self.coco.loadAnns(annotations_ids)\n",
        "        for idx, a in enumerate(coco_annotations):\n",
        "\n",
        "            # some annotations have basically no width / height, skip them\n",
        "            if a['area'] == 0:\n",
        "                continue\n",
        "            \n",
        "            if a['bbox'][2] < 1 or a['bbox'][3] < 1:\n",
        "                continue\n",
        "\n",
        "            annotation = np.zeros((1, 5))\n",
        "            annotation[0, :4] = a['bbox']\n",
        "            annotation[0, 4] = self.coco_label_to_label(a['category_id'])\n",
        "            annotations = np.append(annotations, annotation, axis=0)\n",
        "\n",
        "        # transform from [x, y, w, h] to [x1, y1, x2, y2]\n",
        "        annotations[:, 2] = annotations[:, 0] + annotations[:, 2]\n",
        "        annotations[:, 3] = annotations[:, 1] + annotations[:, 3]\n",
        "\n",
        "        return annotations\n",
        "\n",
        "    def coco_label_to_label(self, coco_label):\n",
        "        return self.coco_labels_inverse[coco_label]\n",
        "\n",
        "    def label_to_coco_label(self, label):\n",
        "        return self.coco_labels[label]\n",
        "\n",
        "    def num_classes(self):\n",
        "        return len(self.classes)\n",
        "\n",
        "\n",
        "def collater(data):\n",
        "    imgs = [s['img'] for s in data]\n",
        "    annots = [s['annot'] for s in data]\n",
        "    scales = [s['scale'] for s in data]\n",
        "\n",
        "    imgs = torch.from_numpy(np.stack(imgs, axis=0))\n",
        "\n",
        "    max_num_annots = max(annot.shape[0] for annot in annots)\n",
        "\n",
        "    if max_num_annots > 0:\n",
        "\n",
        "        annot_padded = torch.ones((len(annots), max_num_annots, 5)) * -1\n",
        "\n",
        "        if max_num_annots > 0:\n",
        "            for idx, annot in enumerate(annots):\n",
        "                if annot.shape[0] > 0:\n",
        "                    annot_padded[idx, :annot.shape[0], :] = annot\n",
        "    else:\n",
        "        annot_padded = torch.ones((len(annots), 1, 5)) * -1\n",
        "\n",
        "    imgs = imgs.permute(0, 3, 1, 2)\n",
        "\n",
        "    return {'img': imgs, 'annot': annot_padded, 'scale': scales}\n",
        "\n",
        "\n",
        "class Resizer(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample, common_size=512):\n",
        "        image, annots = sample['img'], sample['annot']\n",
        "        height, width, _ = image.shape\n",
        "        if height > width:\n",
        "            scale = common_size / height\n",
        "            resized_height = common_size\n",
        "            resized_width = int(width * scale)\n",
        "        else:\n",
        "            scale = common_size / width\n",
        "            resized_height = int(height * scale)\n",
        "            resized_width = common_size\n",
        "\n",
        "        image = cv2.resize(image, (resized_width, resized_height))\n",
        "\n",
        "        new_image = np.zeros((common_size, common_size, 3))\n",
        "        new_image[0:resized_height, 0:resized_width] = image\n",
        "\n",
        "        annots[:, :4] *= scale\n",
        "\n",
        "        return {'img': torch.from_numpy(new_image), 'annot': torch.from_numpy(annots), 'scale': scale}\n",
        "\n",
        "\n",
        "class Augmenter(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample, flip_x=0.5):\n",
        "        if np.random.rand() < flip_x:\n",
        "            image, annots = sample['img'], sample['annot']\n",
        "            image = image[:, ::-1, :]\n",
        "\n",
        "            rows, cols, channels = image.shape\n",
        "\n",
        "            x1 = annots[:, 0].copy()\n",
        "            x2 = annots[:, 2].copy()\n",
        "\n",
        "            x_tmp = x1.copy()\n",
        "\n",
        "            annots[:, 0] = cols - x2\n",
        "            annots[:, 2] = cols - x_tmp\n",
        "\n",
        "            sample = {'img': image, 'annot': annots}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class Normalizer(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.mean = np.array([[[0.485, 0.456, 0.406]]])\n",
        "        self.std = np.array([[[0.229, 0.224, 0.225]]])\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, annots = sample['img'], sample['annot']\n",
        "\n",
        "        return {'img': ((image.astype(np.float32) - self.mean) / self.std), 'annot': annots}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vnEWZ2y9vVc"
      },
      "source": [
        "UTILS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFkmngIC9xge"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class BBoxTransform(nn.Module):\n",
        "\n",
        "    def __init__(self, mean=None, std=None):\n",
        "        super(BBoxTransform, self).__init__()\n",
        "        if mean is None:\n",
        "            self.mean = torch.from_numpy(np.array([0, 0, 0, 0]).astype(np.float32))\n",
        "        else:\n",
        "            self.mean = mean\n",
        "        if std is None:\n",
        "            self.std = torch.from_numpy(np.array([0.1, 0.1, 0.2, 0.2]).astype(np.float32))\n",
        "        else:\n",
        "            self.std = std\n",
        "        if torch.cuda.is_available():\n",
        "            self.mean = self.mean.cuda()\n",
        "            self.std = self.std.cuda()\n",
        "\n",
        "    def forward(self, boxes, deltas):\n",
        "\n",
        "        widths = boxes[:, :, 2] - boxes[:, :, 0]\n",
        "        heights = boxes[:, :, 3] - boxes[:, :, 1]\n",
        "        ctr_x = boxes[:, :, 0] + 0.5 * widths\n",
        "        ctr_y = boxes[:, :, 1] + 0.5 * heights\n",
        "\n",
        "        dx = deltas[:, :, 0] * self.std[0] + self.mean[0]\n",
        "        dy = deltas[:, :, 1] * self.std[1] + self.mean[1]\n",
        "        dw = deltas[:, :, 2] * self.std[2] + self.mean[2]\n",
        "        dh = deltas[:, :, 3] * self.std[3] + self.mean[3]\n",
        "\n",
        "        pred_ctr_x = ctr_x + dx * widths\n",
        "        pred_ctr_y = ctr_y + dy * heights\n",
        "        pred_w = torch.exp(dw) * widths\n",
        "        pred_h = torch.exp(dh) * heights\n",
        "\n",
        "        pred_boxes_x1 = pred_ctr_x - 0.5 * pred_w\n",
        "        pred_boxes_y1 = pred_ctr_y - 0.5 * pred_h\n",
        "        pred_boxes_x2 = pred_ctr_x + 0.5 * pred_w\n",
        "        pred_boxes_y2 = pred_ctr_y + 0.5 * pred_h\n",
        "\n",
        "        pred_boxes = torch.stack([pred_boxes_x1, pred_boxes_y1, pred_boxes_x2, pred_boxes_y2], dim=2)\n",
        "\n",
        "        return pred_boxes\n",
        "\n",
        "\n",
        "class ClipBoxes(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ClipBoxes, self).__init__()\n",
        "\n",
        "    def forward(self, boxes, img):\n",
        "        batch_size, num_channels, height, width = img.shape\n",
        "\n",
        "        boxes[:, :, 0] = torch.clamp(boxes[:, :, 0], min=0)\n",
        "        boxes[:, :, 1] = torch.clamp(boxes[:, :, 1], min=0)\n",
        "\n",
        "        boxes[:, :, 2] = torch.clamp(boxes[:, :, 2], max=width)\n",
        "        boxes[:, :, 3] = torch.clamp(boxes[:, :, 3], max=height)\n",
        "\n",
        "        return boxes\n",
        "\n",
        "\n",
        "class Anchors(nn.Module):\n",
        "    def __init__(self, pyramid_levels=None, strides=None, sizes=None, ratios=None, scales=None):\n",
        "        super(Anchors, self).__init__()\n",
        "\n",
        "        if pyramid_levels is None:\n",
        "            self.pyramid_levels = [3, 4, 5, 6, 7]\n",
        "        if strides is None:\n",
        "            self.strides = [2 ** x for x in self.pyramid_levels]\n",
        "        if sizes is None:\n",
        "            self.sizes = [2 ** (x + 2) for x in self.pyramid_levels]\n",
        "        if ratios is None:\n",
        "            self.ratios = np.array([0.5, 1, 2])\n",
        "        if scales is None:\n",
        "            self.scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
        "\n",
        "    def forward(self, image):\n",
        "\n",
        "        image_shape = image.shape[2:]\n",
        "        image_shape = np.array(image_shape)\n",
        "        image_shapes = [(image_shape + 2 ** x - 1) // (2 ** x) for x in self.pyramid_levels]\n",
        "\n",
        "        all_anchors = np.zeros((0, 4)).astype(np.float32)\n",
        "\n",
        "        for idx, p in enumerate(self.pyramid_levels):\n",
        "            anchors = generate_anchors(base_size=self.sizes[idx], ratios=self.ratios, scales=self.scales)\n",
        "            shifted_anchors = shift(image_shapes[idx], self.strides[idx], anchors)\n",
        "            all_anchors = np.append(all_anchors, shifted_anchors, axis=0)\n",
        "\n",
        "        all_anchors = np.expand_dims(all_anchors, axis=0)\n",
        "\n",
        "        anchors = torch.from_numpy(all_anchors.astype(np.float32))\n",
        "        if torch.cuda.is_available():\n",
        "            anchors = anchors.cuda()\n",
        "        return anchors\n",
        "\n",
        "\n",
        "def generate_anchors(base_size=16, ratios=None, scales=None):\n",
        "    if ratios is None:\n",
        "        ratios = np.array([0.5, 1, 2])\n",
        "\n",
        "    if scales is None:\n",
        "        scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
        "\n",
        "    num_anchors = len(ratios) * len(scales)\n",
        "    anchors = np.zeros((num_anchors, 4))\n",
        "    anchors[:, 2:] = base_size * np.tile(scales, (2, len(ratios))).T\n",
        "    areas = anchors[:, 2] * anchors[:, 3]\n",
        "    anchors[:, 2] = np.sqrt(areas / np.repeat(ratios, len(scales)))\n",
        "    anchors[:, 3] = anchors[:, 2] * np.repeat(ratios, len(scales))\n",
        "    anchors[:, 0::2] -= np.tile(anchors[:, 2] * 0.5, (2, 1)).T\n",
        "    anchors[:, 1::2] -= np.tile(anchors[:, 3] * 0.5, (2, 1)).T\n",
        "\n",
        "    return anchors\n",
        "\n",
        "\n",
        "def compute_shape(image_shape, pyramid_levels):\n",
        "    image_shape = np.array(image_shape[:2])\n",
        "    image_shapes = [(image_shape + 2 ** x - 1) // (2 ** x) for x in pyramid_levels]\n",
        "    return image_shapes\n",
        "\n",
        "\n",
        "def shift(shape, stride, anchors):\n",
        "    shift_x = (np.arange(0, shape[1]) + 0.5) * stride\n",
        "    shift_y = (np.arange(0, shape[0]) + 0.5) * stride\n",
        "    shift_x, shift_y = np.meshgrid(shift_x, shift_y)\n",
        "    shifts = np.vstack((\n",
        "        shift_x.ravel(), shift_y.ravel(),\n",
        "        shift_x.ravel(), shift_y.ravel()\n",
        "    )).transpose()\n",
        "\n",
        "    A = anchors.shape[0]\n",
        "    K = shifts.shape[0]\n",
        "    all_anchors = (anchors.reshape((1, A, 4)) + shifts.reshape((1, K, 4)).transpose((1, 0, 2)))\n",
        "    all_anchors = all_anchors.reshape((K * A, 4))\n",
        "\n",
        "    return all_anchors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7guXUDr9vYN"
      },
      "source": [
        "# LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH8Nvk1R-A1p"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def calc_iou(a, b):\n",
        "\n",
        "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
        "    iw = torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]) - torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0])\n",
        "    ih = torch.min(torch.unsqueeze(a[:, 3], dim=1), b[:, 3]) - torch.max(torch.unsqueeze(a[:, 1], 1), b[:, 1])\n",
        "    iw = torch.clamp(iw, min=0)\n",
        "    ih = torch.clamp(ih, min=0)\n",
        "    ua = torch.unsqueeze((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), dim=1) + area - iw * ih\n",
        "    ua = torch.clamp(ua, min=1e-8)\n",
        "    intersection = iw * ih\n",
        "    IoU = intersection / ua\n",
        "\n",
        "    return IoU\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FocalLoss, self).__init__()\n",
        "\n",
        "    def forward(self, classifications, regressions, anchors, annotations):\n",
        "        alpha = 0.25\n",
        "        gamma = 2.0\n",
        "        batch_size = classifications.shape[0]\n",
        "        classification_losses = []\n",
        "        regression_losses = []\n",
        "\n",
        "        anchor = anchors[0, :, :]\n",
        "\n",
        "        anchor_widths = anchor[:, 2] - anchor[:, 0]\n",
        "        anchor_heights = anchor[:, 3] - anchor[:, 1]\n",
        "        anchor_ctr_x = anchor[:, 0] + 0.5 * anchor_widths\n",
        "        anchor_ctr_y = anchor[:, 1] + 0.5 * anchor_heights\n",
        "\n",
        "        for j in range(batch_size):\n",
        "\n",
        "            classification = classifications[j, :, :]\n",
        "            regression = regressions[j, :, :]\n",
        "\n",
        "            bbox_annotation = annotations[j, :, :]\n",
        "            bbox_annotation = bbox_annotation[bbox_annotation[:, 4] != -1]\n",
        "\n",
        "            if bbox_annotation.shape[0] == 0:\n",
        "                if torch.cuda.is_available():\n",
        "                    regression_losses.append(torch.tensor(0).float().cuda())\n",
        "                    classification_losses.append(torch.tensor(0).float().cuda())\n",
        "                else:\n",
        "                    regression_losses.append(torch.tensor(0).float())\n",
        "                    classification_losses.append(torch.tensor(0).float())\n",
        "\n",
        "                continue\n",
        "\n",
        "            classification = torch.clamp(classification, 1e-4, 1.0 - 1e-4)\n",
        "\n",
        "            IoU = calc_iou(anchors[0, :, :], bbox_annotation[:, :4])\n",
        "\n",
        "            IoU_max, IoU_argmax = torch.max(IoU, dim=1)\n",
        "\n",
        "            # compute the loss for classification\n",
        "            targets = torch.ones(classification.shape) * -1\n",
        "            if torch.cuda.is_available():\n",
        "                targets = targets.cuda()\n",
        "\n",
        "            targets[torch.lt(IoU_max, 0.4), :] = 0\n",
        "\n",
        "            positive_indices = torch.ge(IoU_max, 0.5)\n",
        "\n",
        "            num_positive_anchors = positive_indices.sum()\n",
        "\n",
        "            assigned_annotations = bbox_annotation[IoU_argmax, :]\n",
        "\n",
        "            targets[positive_indices, :] = 0\n",
        "            targets[positive_indices, assigned_annotations[positive_indices, 4].long()] = 1\n",
        "\n",
        "            alpha_factor = torch.ones(targets.shape) * alpha\n",
        "            if torch.cuda.is_available():\n",
        "                alpha_factor = alpha_factor.cuda()\n",
        "\n",
        "            alpha_factor = torch.where(torch.eq(targets, 1.), alpha_factor, 1. - alpha_factor)\n",
        "            focal_weight = torch.where(torch.eq(targets, 1.), 1. - classification, classification)\n",
        "            focal_weight = alpha_factor * torch.pow(focal_weight, gamma)\n",
        "\n",
        "            bce = -(targets * torch.log(classification) + (1.0 - targets) * torch.log(1.0 - classification))\n",
        "\n",
        "            cls_loss = focal_weight * bce\n",
        "\n",
        "            zeros = torch.zeros(cls_loss.shape)\n",
        "            if torch.cuda.is_available():\n",
        "                zeros = zeros.cuda()\n",
        "            cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, zeros)\n",
        "\n",
        "            classification_losses.append(cls_loss.sum() / torch.clamp(num_positive_anchors.float(), min=1.0))\n",
        "\n",
        "\n",
        "            if positive_indices.sum() > 0:\n",
        "                assigned_annotations = assigned_annotations[positive_indices, :]\n",
        "\n",
        "                anchor_widths_pi = anchor_widths[positive_indices]\n",
        "                anchor_heights_pi = anchor_heights[positive_indices]\n",
        "                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]\n",
        "                anchor_ctr_y_pi = anchor_ctr_y[positive_indices]\n",
        "\n",
        "                gt_widths = assigned_annotations[:, 2] - assigned_annotations[:, 0]\n",
        "                gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1]\n",
        "                gt_ctr_x = assigned_annotations[:, 0] + 0.5 * gt_widths\n",
        "                gt_ctr_y = assigned_annotations[:, 1] + 0.5 * gt_heights\n",
        "\n",
        "                gt_widths = torch.clamp(gt_widths, min=1)\n",
        "                gt_heights = torch.clamp(gt_heights, min=1)\n",
        "\n",
        "                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi\n",
        "                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi\n",
        "                targets_dw = torch.log(gt_widths / anchor_widths_pi)\n",
        "                targets_dh = torch.log(gt_heights / anchor_heights_pi)\n",
        "\n",
        "                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh))\n",
        "                targets = targets.t()\n",
        "\n",
        "                norm = torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
        "                if torch.cuda.is_available():\n",
        "                    norm = norm.cuda()\n",
        "                targets = targets / norm\n",
        "\n",
        "                regression_diff = torch.abs(targets - regression[positive_indices, :])\n",
        "\n",
        "                regression_loss = torch.where(\n",
        "                    torch.le(regression_diff, 1.0 / 9.0),\n",
        "                    0.5 * 9.0 * torch.pow(regression_diff, 2),\n",
        "                    regression_diff - 0.5 / 9.0\n",
        "                )\n",
        "                regression_losses.append(regression_loss.mean())\n",
        "            else:\n",
        "                if torch.cuda.is_available():\n",
        "                    regression_losses.append(torch.tensor(0).float().cuda())\n",
        "                else:\n",
        "                    regression_losses.append(torch.tensor(0).float())\n",
        "\n",
        "        return torch.stack(classification_losses).mean(dim=0, keepdim=True), torch.stack(regression_losses).mean(dim=0,\n",
        "                                                                                                                 keepdim=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjE42sxV-F68"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Zp_9y7BH-L5Z",
        "outputId": "8fc77f03-dd1e-4fb5-c50a-c90ea3950b2e"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import math\n",
        "from efficientnet_pytorch import EfficientNet as EffNet\n",
        "from torchvision.ops.boxes import nms as nms_torch\n",
        "\n",
        "\n",
        "def nms(dets, thresh):\n",
        "    return nms_torch(dets[:, :4], dets[:, 4], thresh)\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, num_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(num_channels, num_channels, kernel_size=3, stride=1, padding=1, groups=num_channels),\n",
        "            nn.Conv2d(num_channels, num_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(num_features=num_channels, momentum=0.9997, eps=4e-5), nn.ReLU())\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.conv(input)\n",
        "\n",
        "\n",
        "class BiFPN(nn.Module):\n",
        "    def __init__(self, num_channels, epsilon=1e-4):\n",
        "        super(BiFPN, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "        # Conv layers\n",
        "        self.conv6_up = ConvBlock(num_channels)\n",
        "        self.conv5_up = ConvBlock(num_channels)\n",
        "        self.conv4_up = ConvBlock(num_channels)\n",
        "        self.conv3_up = ConvBlock(num_channels)\n",
        "        self.conv4_down = ConvBlock(num_channels)\n",
        "        self.conv5_down = ConvBlock(num_channels)\n",
        "        self.conv6_down = ConvBlock(num_channels)\n",
        "        self.conv7_down = ConvBlock(num_channels)\n",
        "\n",
        "        # Feature scaling layers\n",
        "        self.p6_upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.p5_upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.p4_upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.p3_upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "        self.p4_downsample = nn.MaxPool2d(kernel_size=2)\n",
        "        self.p5_downsample = nn.MaxPool2d(kernel_size=2)\n",
        "        self.p6_downsample = nn.MaxPool2d(kernel_size=2)\n",
        "        self.p7_downsample = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Weight\n",
        "        self.p6_w1 = nn.Parameter(torch.ones(2))\n",
        "        self.p6_w1_relu = nn.ReLU()\n",
        "        self.p5_w1 = nn.Parameter(torch.ones(2))\n",
        "        self.p5_w1_relu = nn.ReLU()\n",
        "        self.p4_w1 = nn.Parameter(torch.ones(2))\n",
        "        self.p4_w1_relu = nn.ReLU()\n",
        "        self.p3_w1 = nn.Parameter(torch.ones(2))\n",
        "        self.p3_w1_relu = nn.ReLU()\n",
        "\n",
        "        self.p4_w2 = nn.Parameter(torch.ones(3))\n",
        "        self.p4_w2_relu = nn.ReLU()\n",
        "        self.p5_w2 = nn.Parameter(torch.ones(3))\n",
        "        self.p5_w2_relu = nn.ReLU()\n",
        "        self.p6_w2 = nn.Parameter(torch.ones(3))\n",
        "        self.p6_w2_relu = nn.ReLU()\n",
        "        self.p7_w2 = nn.Parameter(torch.ones(2))\n",
        "        self.p7_w2_relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "            P7_0 -------------------------- P7_2 -------->\n",
        "\n",
        "            P6_0 ---------- P6_1 ---------- P6_2 -------->\n",
        "\n",
        "            P5_0 ---------- P5_1 ---------- P5_2 -------->\n",
        "\n",
        "            P4_0 ---------- P4_1 ---------- P4_2 -------->\n",
        "\n",
        "            P3_0 -------------------------- P3_2 -------->\n",
        "        \"\"\"\n",
        "\n",
        "        # P3_0, P4_0, P5_0, P6_0 and P7_0\n",
        "        p3_in, p4_in, p5_in, p6_in, p7_in = inputs\n",
        "        # P7_0 to P7_2\n",
        "        # Weights for P6_0 and P7_0 to P6_1\n",
        "        p6_w1 = self.p6_w1_relu(self.p6_w1)\n",
        "        weight = p6_w1 / (torch.sum(p6_w1, dim=0) + self.epsilon)\n",
        "        # Connections for P6_0 and P7_0 to P6_1 respectively\n",
        "        p6_up = self.conv6_up(weight[0] * p6_in + weight[1] * self.p6_upsample(p7_in))\n",
        "        # Weights for P5_0 and P6_0 to P5_1\n",
        "        p5_w1 = self.p5_w1_relu(self.p5_w1)\n",
        "        weight = p5_w1 / (torch.sum(p5_w1, dim=0) + self.epsilon)\n",
        "        # Connections for P5_0 and P6_0 to P5_1 respectively\n",
        "        p5_up = self.conv5_up(weight[0] * p5_in + weight[1] * self.p5_upsample(p6_up))\n",
        "        # Weights for P4_0 and P5_0 to P4_1\n",
        "        p4_w1 = self.p4_w1_relu(self.p4_w1)\n",
        "        weight = p4_w1 / (torch.sum(p4_w1, dim=0) + self.epsilon)\n",
        "        # Connections for P4_0 and P5_0 to P4_1 respectively\n",
        "        p4_up = self.conv4_up(weight[0] * p4_in + weight[1] * self.p4_upsample(p5_up))\n",
        "\n",
        "        # Weights for P3_0 and P4_1 to P3_2\n",
        "        p3_w1 = self.p3_w1_relu(self.p3_w1)\n",
        "        weight = p3_w1 / (torch.sum(p3_w1, dim=0) + self.epsilon)\n",
        "        # Connections for P3_0 and P4_1 to P3_2 respectively\n",
        "        p3_out = self.conv3_up(weight[0] * p3_in + weight[1] * self.p3_upsample(p4_up))\n",
        "\n",
        "        # Weights for P4_0, P4_1 and P3_2 to P4_2\n",
        "        p4_w2 = self.p4_w2_relu(self.p4_w2)\n",
        "        weight = p4_w2 / (torch.sum(p4_w2, dim=0) + self.epsilon)\n",
        "        # Connections for P4_0, P4_1 and P3_2 to P4_2 respectively\n",
        "        p4_out = self.conv4_down(\n",
        "            weight[0] * p4_in + weight[1] * p4_up + weight[2] * self.p4_downsample(p3_out))\n",
        "        # Weights for P5_0, P5_1 and P4_2 to P5_2\n",
        "        p5_w2 = self.p5_w2_relu(self.p5_w2)\n",
        "        weight = p5_w2 / (torch.sum(p5_w2, dim=0) + self.epsilon)\n",
        "        # Connections for P5_0, P5_1 and P4_2 to P5_2 respectively\n",
        "        p5_out = self.conv5_down(\n",
        "            weight[0] * p5_in + weight[1] * p5_up + weight[2] * self.p5_downsample(p4_out))\n",
        "        # Weights for P6_0, P6_1 and P5_2 to P6_2\n",
        "        p6_w2 = self.p6_w2_relu(self.p6_w2)\n",
        "        weight = p6_w2 / (torch.sum(p6_w2, dim=0) + self.epsilon)\n",
        "        # Connections for P6_0, P6_1 and P5_2 to P6_2 respectively\n",
        "        p6_out = self.conv6_down(\n",
        "            weight[0] * p6_in + weight[1] * p6_up + weight[2] * self.p6_downsample(p5_out))\n",
        "        # Weights for P7_0 and P6_2 to P7_2\n",
        "        p7_w2 = self.p7_w2_relu(self.p7_w2)\n",
        "        weight = p7_w2 / (torch.sum(p7_w2, dim=0) + self.epsilon)\n",
        "        # Connections for P7_0 and P6_2 to P7_2\n",
        "        p7_out = self.conv7_down(weight[0] * p7_in + weight[1] * self.p7_downsample(p6_out))\n",
        "\n",
        "        return p3_out, p4_out, p5_out, p6_out, p7_out\n",
        "\n",
        "\n",
        "class Regressor(nn.Module):\n",
        "    def __init__(self, in_channels, num_anchors, num_layers):\n",
        "        super(Regressor, self).__init__()\n",
        "        layers = []\n",
        "        for _ in range(num_layers):\n",
        "            layers.append(nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1))\n",
        "            layers.append(nn.ReLU(True))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        self.header = nn.Conv2d(in_channels, num_anchors * 4, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputs = self.layers(inputs)\n",
        "        inputs = self.header(inputs)\n",
        "        output = inputs.permute(0, 2, 3, 1)\n",
        "        return output.contiguous().view(output.shape[0], -1, 4)\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_channels, num_anchors, num_classes, num_layers):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.num_anchors = num_anchors\n",
        "        self.num_classes = num_classes\n",
        "        layers = []\n",
        "        for _ in range(num_layers):\n",
        "            layers.append(nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1))\n",
        "            layers.append(nn.ReLU(True))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        self.header = nn.Conv2d(in_channels, num_anchors * num_classes, kernel_size=3, stride=1, padding=1)\n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputs = self.layers(inputs)\n",
        "        inputs = self.header(inputs)\n",
        "        inputs = self.act(inputs)\n",
        "        inputs = inputs.permute(0, 2, 3, 1)\n",
        "        output = inputs.contiguous().view(inputs.shape[0], inputs.shape[1], inputs.shape[2], self.num_anchors,\n",
        "                                          self.num_classes)\n",
        "        return output.contiguous().view(output.shape[0], -1, self.num_classes)\n",
        "\n",
        "\n",
        "class EfficientNet(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(EfficientNet, self).__init__()\n",
        "        model = EffNet.from_pretrained('efficientnet-b0')\n",
        "        del model._conv_head\n",
        "        del model._bn1\n",
        "        del model._avg_pooling\n",
        "        del model._dropout\n",
        "        del model._fc\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model._swish(self.model._bn0(self.model._conv_stem(x)))\n",
        "        feature_maps = []\n",
        "        for idx, block in enumerate(self.model._blocks):\n",
        "            drop_connect_rate = self.model._global_params.drop_connect_rate\n",
        "            if drop_connect_rate:\n",
        "                drop_connect_rate *= float(idx) / len(self.model._blocks)\n",
        "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
        "            if block._depthwise_conv.stride == [2, 2]:\n",
        "                feature_maps.append(x)\n",
        "\n",
        "        return feature_maps[1:]\n",
        "\n",
        "\n",
        "class EfficientDet(nn.Module):\n",
        "    def __init__(self, num_anchors=9, num_classes=20, compound_coef=0):\n",
        "        super(EfficientDet, self).__init__()\n",
        "        self.compound_coef = compound_coef\n",
        "\n",
        "        self.num_channels = [64, 88, 112, 160, 224, 288, 384, 384][self.compound_coef]\n",
        "\n",
        "        self.conv3 = nn.Conv2d(40, self.num_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv4 = nn.Conv2d(80, self.num_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv5 = nn.Conv2d(192, self.num_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv6 = nn.Conv2d(192, self.num_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv7 = nn.Sequential(nn.ReLU(),\n",
        "                                   nn.Conv2d(self.num_channels, self.num_channels, kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "        self.bifpn = nn.Sequential(*[BiFPN(self.num_channels) for _ in range(min(2 + self.compound_coef, 8))])\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.regressor = Regressor(in_channels=self.num_channels, num_anchors=num_anchors,\n",
        "                                   num_layers=3 + self.compound_coef // 3)\n",
        "        self.classifier = Classifier(in_channels=self.num_channels, num_anchors=num_anchors, num_classes=num_classes,\n",
        "                                     num_layers=3 + self.compound_coef // 3)\n",
        "\n",
        "        self.anchors = Anchors()\n",
        "        self.regressBoxes = BBoxTransform()\n",
        "        self.clipBoxes = ClipBoxes()\n",
        "        self.focalLoss = FocalLoss()\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "        prior = 0.01\n",
        "\n",
        "        self.classifier.header.weight.data.fill_(0)\n",
        "        self.classifier.header.bias.data.fill_(-math.log((1.0 - prior) / prior))\n",
        "\n",
        "        self.regressor.header.weight.data.fill_(0)\n",
        "        self.regressor.header.bias.data.fill_(0)\n",
        "\n",
        "        self.backbone_net = EfficientNet()\n",
        "\n",
        "    def freeze_bn(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.eval()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if len(inputs) == 2:\n",
        "            is_training = True\n",
        "            img_batch, annotations = inputs\n",
        "        else:\n",
        "            is_training = False\n",
        "            img_batch = inputs\n",
        "\n",
        "        c3, c4, c5 = self.backbone_net(img_batch)\n",
        "        p3 = self.conv3(c3)\n",
        "        p4 = self.conv4(c4)\n",
        "        p5 = self.conv5(c5)\n",
        "        p6 = self.conv6(c5)\n",
        "        p7 = self.conv7(p6)\n",
        "\n",
        "        features = [p3, p4, p5, p6, p7]\n",
        "        features = self.bifpn(features)\n",
        "\n",
        "        regression = torch.cat([self.regressor(feature) for feature in features], dim=1)\n",
        "        classification = torch.cat([self.classifier(feature) for feature in features], dim=1)\n",
        "        anchors = self.anchors(img_batch)\n",
        "\n",
        "        if is_training:\n",
        "            return self.focalLoss(classification, regression, anchors, annotations)\n",
        "        else:\n",
        "            transformed_anchors = self.regressBoxes(anchors, regression)\n",
        "            transformed_anchors = self.clipBoxes(transformed_anchors, img_batch)\n",
        "\n",
        "            scores = torch.max(classification, dim=2, keepdim=True)[0]\n",
        "\n",
        "            scores_over_thresh = (scores > 0.05)[0, :, 0]\n",
        "\n",
        "            if scores_over_thresh.sum() == 0:\n",
        "                return [torch.zeros(0), torch.zeros(0), torch.zeros(0, 4)]\n",
        "\n",
        "            classification = classification[:, scores_over_thresh, :]\n",
        "            transformed_anchors = transformed_anchors[:, scores_over_thresh, :]\n",
        "            scores = scores[:, scores_over_thresh, :]\n",
        "\n",
        "            anchors_nms_idx = nms(torch.cat([transformed_anchors, scores], dim=2)[0, :, :], 0.5)\n",
        "\n",
        "            nms_scores, nms_class = classification[0, anchors_nms_idx, :].max(dim=1)\n",
        "\n",
        "            return [nms_scores, nms_class, transformed_anchors[0, anchors_nms_idx, :]]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    from tensorboardX import SummaryWriter\n",
        "    def count_parameters(model):\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    model = EfficientDet(num_classes=80)\n",
        "    print (count_parameters(model))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='21388428' value='21388428'></progress>100% 20.4M/20.4M [00:00&lt;00:00, 97.4MB/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "4499798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lm4ohZg-F-e"
      },
      "source": [
        "# Training Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avBEBUWv-T8P"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "\n",
        "class Detector():\n",
        "    def __init__(self, verbose=1):\n",
        "        self.system_dict = {};\n",
        "        self.system_dict[\"verbose\"] = verbose;\n",
        "        self.system_dict[\"local\"] = {};\n",
        "        self.system_dict[\"dataset\"] = {};\n",
        "        self.system_dict[\"dataset\"][\"train\"] = {};\n",
        "        self.system_dict[\"dataset\"][\"val\"] = {};\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"status\"] = False;\n",
        "\n",
        "        self.system_dict[\"params\"] = {};\n",
        "        self.system_dict[\"params\"][\"image_size\"] = 512;\n",
        "        self.system_dict[\"params\"][\"batch_size\"] = 8;\n",
        "        self.system_dict[\"params\"][\"num_workers\"] = 3;\n",
        "        self.system_dict[\"params\"][\"use_gpu\"] = True;\n",
        "        self.system_dict[\"params\"][\"gpu_devices\"] = [0];\n",
        "        self.system_dict[\"params\"][\"lr\"] = 0.0001;\n",
        "        self.system_dict[\"params\"][\"num_epochs\"] = 10;\n",
        "        self.system_dict[\"params\"][\"val_interval\"] = 1;\n",
        "        self.system_dict[\"params\"][\"es_min_delta\"] = 0.0;\n",
        "        self.system_dict[\"params\"][\"es_patience\"] = 0;\n",
        "\n",
        "\n",
        "        self.system_dict[\"output\"] = {};\n",
        "        self.system_dict[\"output\"][\"log_path\"] = \"tensorboard/signatrix_efficientdet_coco\";\n",
        "        self.system_dict[\"output\"][\"saved_path\"] = \"trained/\";\n",
        "        self.system_dict[\"output\"][\"best_epoch\"] = 0;\n",
        "        self.system_dict[\"output\"][\"best_loss\"] = 1e5;\n",
        "\n",
        "\n",
        "\n",
        "    def Train_Dataset(self, root_dir, coco_dir, img_dir, set_dir, batch_size=8, image_size=512, use_gpu=True, num_workers=3):\n",
        "        self.system_dict[\"dataset\"][\"train\"][\"root_dir\"] = root_dir;\n",
        "        self.system_dict[\"dataset\"][\"train\"][\"coco_dir\"] = coco_dir;\n",
        "        self.system_dict[\"dataset\"][\"train\"][\"img_dir\"] = img_dir;\n",
        "        self.system_dict[\"dataset\"][\"train\"][\"set_dir\"] = set_dir;\n",
        "\n",
        "\n",
        "        self.system_dict[\"params\"][\"batch_size\"] = batch_size;\n",
        "        self.system_dict[\"params\"][\"image_size\"] = image_size;\n",
        "        self.system_dict[\"params\"][\"use_gpu\"] = use_gpu;\n",
        "        self.system_dict[\"params\"][\"num_workers\"] = num_workers;\n",
        "\n",
        "        if(self.system_dict[\"params\"][\"use_gpu\"]):\n",
        "            if torch.cuda.is_available():\n",
        "                self.system_dict[\"local\"][\"num_gpus\"] = torch.cuda.device_count()\n",
        "                torch.cuda.manual_seed(123)\n",
        "            else:\n",
        "                self.system_dict[\"local\"][\"num_gpus\"] = 1\n",
        "                torch.manual_seed(123)\n",
        "\n",
        "        self.system_dict[\"local\"][\"training_params\"] = {\"batch_size\": self.system_dict[\"params\"][\"batch_size\"] * self.system_dict[\"local\"][\"num_gpus\"],\n",
        "                                                           \"shuffle\": True,\n",
        "                                                           \"drop_last\": True,\n",
        "                                                           \"collate_fn\": collater,\n",
        "                                                           \"num_workers\": self.system_dict[\"params\"][\"num_workers\"]}\n",
        "\n",
        "        self.system_dict[\"local\"][\"training_set\"] = CocoDataset(root_dir=self.system_dict[\"dataset\"][\"train\"][\"root_dir\"] + \"/\" + self.system_dict[\"dataset\"][\"train\"][\"coco_dir\"],\n",
        "                                                            img_dir = self.system_dict[\"dataset\"][\"train\"][\"img_dir\"],\n",
        "                                                            set_dir = self.system_dict[\"dataset\"][\"train\"][\"set_dir\"],\n",
        "                                                            transform = transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
        "        \n",
        "        self.system_dict[\"local\"][\"training_generator\"] = DataLoader(self.system_dict[\"local\"][\"training_set\"], \n",
        "                                                                    **self.system_dict[\"local\"][\"training_params\"]);\n",
        "\n",
        "\n",
        "    def Val_Dataset(self, root_dir, coco_dir, img_dir, set_dir):\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"status\"] = True;\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"root_dir\"] = root_dir;\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"coco_dir\"] = coco_dir;\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"img_dir\"] = img_dir;\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"set_dir\"] = set_dir;     \n",
        "\n",
        "        self.system_dict[\"local\"][\"val_params\"] = {\"batch_size\": self.system_dict[\"params\"][\"batch_size\"],\n",
        "                                                   \"shuffle\": False,\n",
        "                                                   \"drop_last\": False,\n",
        "                                                   \"collate_fn\": collater,\n",
        "                                                   \"num_workers\": self.system_dict[\"params\"][\"num_workers\"]}\n",
        "\n",
        "        self.system_dict[\"local\"][\"val_set\"] = CocoDataset(root_dir=self.system_dict[\"dataset\"][\"val\"][\"root_dir\"] + \"/\" + self.system_dict[\"dataset\"][\"val\"][\"coco_dir\"], \n",
        "                                                    img_dir = self.system_dict[\"dataset\"][\"val\"][\"img_dir\"],\n",
        "                                                    set_dir = self.system_dict[\"dataset\"][\"val\"][\"set_dir\"],\n",
        "                                                    transform=transforms.Compose([Normalizer(), Resizer()]))\n",
        "        \n",
        "        self.system_dict[\"local\"][\"test_generator\"] = DataLoader(self.system_dict[\"local\"][\"val_set\"], \n",
        "                                                                **self.system_dict[\"local\"][\"val_params\"])\n",
        "\n",
        "\n",
        "    def Model(self,gpu_devices=[0]):\n",
        "        num_classes = self.system_dict[\"local\"][\"training_set\"].num_classes();\n",
        "        efficientdet = EfficientDet(num_classes=num_classes)\n",
        "\n",
        "        if self.system_dict[\"params\"][\"use_gpu\"]:\n",
        "            self.system_dict[\"params\"][\"gpu_devices\"] = gpu_devices\n",
        "            if len(self.system_dict[\"params\"][\"gpu_devices\"])==1:\n",
        "                os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.system_dict[\"params\"][\"gpu_devices\"][0])\n",
        "            else:\n",
        "                os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([str(id) for id in self.system_dict[\"params\"][\"gpu_devices\"]])\n",
        "            self.system_dict[\"local\"][\"device\"] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "            efficientdet = efficientdet.to(self.system_dict[\"local\"][\"device\"])\n",
        "            efficientdet= torch.nn.DataParallel(efficientdet).to(self.system_dict[\"local\"][\"device\"])\n",
        "\n",
        "        self.system_dict[\"local\"][\"model\"] = efficientdet;\n",
        "        self.system_dict[\"local\"][\"model\"].train();\n",
        "\n",
        "\n",
        "    def Set_Hyperparams(self, lr=0.0001, val_interval=1, es_min_delta=0.0, es_patience=0):\n",
        "        self.system_dict[\"params\"][\"lr\"] = lr;\n",
        "        self.system_dict[\"params\"][\"val_interval\"] = val_interval;\n",
        "        self.system_dict[\"params\"][\"es_min_delta\"] = es_min_delta;\n",
        "        self.system_dict[\"params\"][\"es_patience\"] = es_patience;\n",
        "\n",
        "\n",
        "        self.system_dict[\"local\"][\"optimizer\"] = torch.optim.Adam(self.system_dict[\"local\"][\"model\"].parameters(), \n",
        "                                                                    self.system_dict[\"params\"][\"lr\"]);\n",
        "\n",
        "        self.system_dict[\"local\"][\"scheduler\"] = torch.optim.lr_scheduler.ReduceLROnPlateau(self.system_dict[\"local\"][\"optimizer\"], \n",
        "                                                                    patience=3, verbose=True)\n",
        "\n",
        "\n",
        "    def Train(self, num_epochs=2, model_output_dir=\"trained/\"):\n",
        "        self.system_dict[\"output\"][\"log_path\"] = \"tensorboard/signatrix_efficientdet_coco\";\n",
        "        self.system_dict[\"output\"][\"saved_path\"] = model_output_dir;\n",
        "        self.system_dict[\"params\"][\"num_epochs\"] = num_epochs;\n",
        "\n",
        "        if os.path.isdir(self.system_dict[\"output\"][\"log_path\"]):\n",
        "            shutil.rmtree(self.system_dict[\"output\"][\"log_path\"])\n",
        "        os.makedirs(self.system_dict[\"output\"][\"log_path\"])\n",
        "\n",
        "        if os.path.isdir(self.system_dict[\"output\"][\"saved_path\"]):\n",
        "            shutil.rmtree(self.system_dict[\"output\"][\"saved_path\"])\n",
        "        os.makedirs(self.system_dict[\"output\"][\"saved_path\"])\n",
        "\n",
        "        writer = SummaryWriter(self.system_dict[\"output\"][\"log_path\"])\n",
        "\n",
        "        num_iter_per_epoch = len(self.system_dict[\"local\"][\"training_generator\"])\n",
        "\n",
        "        if(self.system_dict[\"dataset\"][\"val\"][\"status\"]):\n",
        "            \n",
        "            for epoch in range(self.system_dict[\"params\"][\"num_epochs\"]):\n",
        "                self.system_dict[\"local\"][\"model\"].train()\n",
        "\n",
        "                epoch_loss = []\n",
        "                progress_bar = tqdm(self.system_dict[\"local\"][\"training_generator\"])\n",
        "                for iter, data in enumerate(progress_bar):\n",
        "                    try:\n",
        "                        self.system_dict[\"local\"][\"optimizer\"].zero_grad()\n",
        "                        if torch.cuda.is_available():\n",
        "                            cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].to(self.system_dict[\"local\"][\"device\"]).float(), data['annot'].to(self.system_dict[\"local\"][\"device\"])])\n",
        "                        else:\n",
        "                            cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].float(), data['annot']])\n",
        "\n",
        "                        cls_loss = cls_loss.mean()\n",
        "                        reg_loss = reg_loss.mean()\n",
        "                        loss = cls_loss + reg_loss\n",
        "                        if loss == 0:\n",
        "                            continue\n",
        "                        loss.backward()\n",
        "                        torch.nn.utils.clip_grad_norm_(self.system_dict[\"local\"][\"model\"].parameters(), 0.1)\n",
        "                        self.system_dict[\"local\"][\"optimizer\"].step()\n",
        "                        epoch_loss.append(float(loss))\n",
        "                        total_loss = np.mean(epoch_loss)\n",
        "                        print( \n",
        "                            'Epoch: {}/{}. Iteration: {}/{}. Cls loss: {:.5f}. Reg loss: {:.5f}. Batch loss: {:.5f} Total loss: {:.5f}'.format(\n",
        "                                epoch + 1, self.system_dict[\"params\"][\"num_epochs\"], iter + 1, num_iter_per_epoch, cls_loss, reg_loss, loss,\n",
        "                                total_loss))\n",
        "                        progress_bar.set_description(\n",
        "                            'Epoch: {}/{}. Iteration: {}/{}. Cls loss: {:.5f}. Reg loss: {:.5f}. Batch loss: {:.5f} Total loss: {:.5f}'.format(\n",
        "                                epoch + 1, self.system_dict[\"params\"][\"num_epochs\"], iter + 1, num_iter_per_epoch, cls_loss, reg_loss, loss,\n",
        "                                total_loss))\n",
        "                        writer.add_scalar('Train/Total_loss', total_loss, epoch * num_iter_per_epoch + iter)\n",
        "                        writer.add_scalar('Train/Regression_loss', reg_loss, epoch * num_iter_per_epoch + iter)\n",
        "                        writer.add_scalar('Train/Classfication_loss (focal loss)', cls_loss, epoch * num_iter_per_epoch + iter)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "                        continue\n",
        "                self.system_dict[\"local\"][\"scheduler\"].step(np.mean(epoch_loss))\n",
        "\n",
        "                if epoch % self.system_dict[\"params\"][\"val_interval\"] == 0:\n",
        "\n",
        "                    self.system_dict[\"local\"][\"model\"].eval()\n",
        "                    loss_regression_ls = []\n",
        "                    loss_classification_ls = []\n",
        "                    for iter, data in enumerate(self.system_dict[\"local\"][\"test_generator\"]):\n",
        "                        with torch.no_grad():\n",
        "                            if torch.cuda.is_available():\n",
        "                                cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].to(self.system_dict[\"local\"][\"device\"]).float(), data['annot'].to(self.system_dict[\"local\"][\"device\"])])\n",
        "                            else:\n",
        "                                cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].float(), data['annot']])\n",
        "\n",
        "                            cls_loss = cls_loss.mean()\n",
        "                            reg_loss = reg_loss.mean()\n",
        "\n",
        "                            loss_classification_ls.append(float(cls_loss))\n",
        "                            loss_regression_ls.append(float(reg_loss))\n",
        "\n",
        "                    cls_loss = np.mean(loss_classification_ls)\n",
        "                    reg_loss = np.mean(loss_regression_ls)\n",
        "                    loss = cls_loss + reg_loss\n",
        "\n",
        "                    print(\n",
        "                        'Epoch: {}/{}. Classification loss: {:1.5f}. Regression loss: {:1.5f}. Total loss: {:1.5f}'.format(\n",
        "                            epoch + 1, self.system_dict[\"params\"][\"num_epochs\"], cls_loss, reg_loss,\n",
        "                            np.mean(loss)))\n",
        "                    writer.add_scalar('Val/Total_loss', loss, epoch)\n",
        "                    writer.add_scalar('Val/Regression_loss', reg_loss, epoch)\n",
        "                    writer.add_scalar('Val/Classfication_loss (focal loss)', cls_loss, epoch)\n",
        "\n",
        "                    if loss + self.system_dict[\"params\"][\"es_min_delta\"] < self.system_dict[\"output\"][\"best_loss\"]:\n",
        "                        self.system_dict[\"output\"][\"best_loss\"] = loss\n",
        "                        self.system_dict[\"output\"][\"best_epoch\"] = epoch\n",
        "                        torch.save(self.system_dict[\"local\"][\"model\"], \n",
        "                            os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.pth\"))\n",
        "\n",
        "                        dummy_input = torch.rand(1, 3, 512, 512)\n",
        "                        if torch.cuda.is_available():\n",
        "                            dummy_input = dummy_input.cuda()\n",
        "                        if isinstance(self.system_dict[\"local\"][\"model\"], nn.DataParallel):\n",
        "                            self.system_dict[\"local\"][\"model\"].module.backbone_net.model.set_swish(memory_efficient=False)\n",
        "\n",
        "                            torch.onnx.export(self.system_dict[\"local\"][\"model\"].module, dummy_input,\n",
        "                                              os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.onnx\"),\n",
        "                                              verbose=False,\n",
        "                                              opset_version=11)\n",
        "                            self.system_dict[\"local\"][\"model\"].module.backbone_net.model.set_swish(memory_efficient=True)\n",
        "                        else:\n",
        "                            self.system_dict[\"local\"][\"model\"].backbone_net.model.set_swish(memory_efficient=False)\n",
        "\n",
        "                            torch.onnx.export(self.system_dict[\"local\"][\"model\"], dummy_input,\n",
        "                                              os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.onnx\"),\n",
        "                                              verbose=False,\n",
        "                                              opset_version = 11)\n",
        "                            self.system_dict[\"local\"][\"model\"].backbone_net.model.set_swish(memory_efficient=True)\n",
        "\n",
        "                    # Early stopping\n",
        "                    if epoch - self.system_dict[\"output\"][\"best_epoch\"] > self.system_dict[\"params\"][\"es_patience\"] > 0:\n",
        "                        print(\"Stop training at epoch {}. The lowest loss achieved is {}\".format(epoch, loss))\n",
        "                        break\n",
        "\n",
        "        else:\n",
        "            for epoch in range(self.system_dict[\"params\"][\"num_epochs\"]):\n",
        "                self.system_dict[\"local\"][\"model\"].train()\n",
        "\n",
        "                epoch_loss = []\n",
        "                progress_bar = tqdm(self.system_dict[\"local\"][\"training_generator\"])\n",
        "                for iter, data in enumerate(progress_bar):\n",
        "                    try:\n",
        "                        self.system_dict[\"local\"][\"optimizer\"].zero_grad()\n",
        "                        if torch.cuda.is_available():\n",
        "                            cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].to(self.system_dict[\"local\"][\"device\"]).float(), data['annot'].to(self.system_dict[\"local\"][\"device\"])])\n",
        "                        else:\n",
        "                            cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].float(), data['annot']])\n",
        "\n",
        "                        cls_loss = cls_loss.mean()\n",
        "                        reg_loss = reg_loss.mean()\n",
        "                        loss = cls_loss + reg_loss\n",
        "                        if loss == 0:\n",
        "                            continue\n",
        "                        loss.backward()\n",
        "                        torch.nn.utils.clip_grad_norm_(self.system_dict[\"local\"][\"model\"].parameters(), 0.1)\n",
        "                        self.system_dict[\"local\"][\"optimizer\"].step()\n",
        "                        epoch_loss.append(float(loss))\n",
        "                        total_loss = np.mean(epoch_loss)\n",
        "\n",
        "                        progress_bar.set_description(\n",
        "                            'Epoch: {}/{}. Iteration: {}/{}. Cls loss: {:.5f}. Reg loss: {:.5f}. Batch loss: {:.5f} Total loss: {:.5f}'.format(\n",
        "                                epoch + 1, self.system_dict[\"params\"][\"num_epochs\"], iter + 1, num_iter_per_epoch, cls_loss, reg_loss, loss,\n",
        "                                total_loss))\n",
        "                        writer.add_scalar('Train/Total_loss', total_loss, epoch * num_iter_per_epoch + iter)\n",
        "                        writer.add_scalar('Train/Regression_loss', reg_loss, epoch * num_iter_per_epoch + iter)\n",
        "                        writer.add_scalar('Train/Classfication_loss (focal loss)', cls_loss, epoch * num_iter_per_epoch + iter)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "                        continue\n",
        "                self.system_dict[\"local\"][\"scheduler\"].step(np.mean(epoch_loss))\n",
        "\n",
        "\n",
        "                torch.save(self.system_dict[\"local\"][\"model\"], \n",
        "                    os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.pth\"))\n",
        "\n",
        "                dummy_input = torch.rand(1, 3, 512, 512)\n",
        "                if torch.cuda.is_available():\n",
        "                    dummy_input = dummy_input.to(self.system_dict[\"local\"][\"device\"])\n",
        "                if isinstance(self.system_dict[\"local\"][\"model\"], nn.DataParallel):\n",
        "                    self.system_dict[\"local\"][\"model\"].module.backbone_net.model.set_swish(memory_efficient=False)\n",
        "\n",
        "                    try:\n",
        "                        torch.onnx.export(self.system_dict[\"local\"][\"model\"].module, dummy_input,\n",
        "                                          os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.onnx\"),\n",
        "                                          verbose=False,\n",
        "                                          opset_version=11)\n",
        "                    except:\n",
        "                        print('faild onnx export')\n",
        "                        continue\n",
        "                    self.system_dict[\"local\"][\"model\"].module.backbone_net.model.set_swish(memory_efficient=True)\n",
        "                else:\n",
        "                    self.system_dict[\"local\"][\"model\"].backbone_net.model.set_swish(memory_efficient=False)\n",
        "\n",
        "                    torch.onnx.export(self.system_dict[\"local\"][\"model\"], dummy_input,\n",
        "                                      os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.onnx\"),\n",
        "                                      verbose=False,\n",
        "                                      opset_version=11)\n",
        "                    self.system_dict[\"local\"][\"model\"].backbone_net.model.set_swish(memory_efficient=True)\n",
        "\n",
        "\n",
        "        writer.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zumCON4KQfnU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5l9rWmT-v-1",
        "outputId": "00d49794-ac0a-4146-d2d4-fe7b72fecbe0"
      },
      "source": [
        "gtf = Detector()\n",
        "\n",
        "#directs the model towards file structure\n",
        "root_dir = \"./\";\n",
        "coco_dir = \"space/Fruit\";\n",
        "img_dir = \"./\";\n",
        "set_dir = \"Images\";\n",
        "\n",
        "gtf.Train_Dataset(root_dir, coco_dir, img_dir, set_dir, batch_size=8, image_size=512, use_gpu=True, num_workers=4)\n",
        "gtf.Model()\n",
        "gtf.Set_Hyperparams(lr=0.0001, val_interval=1, es_min_delta=0.0, es_patience=0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded pretrained weights for efficientnet-b0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFF9gdeJ_FNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a2d8eb8-40ca-4ec1-8f19-8f0a67302a46"
      },
      "source": [
        "%%time\n",
        "gtf.Train(num_epochs=100, model_output_dir=\"drive/MyDrive/trained_weight/\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 1/100. Iteration: 16/16. Cls loss: 0.74195. Reg loss: 0.88077. Batch loss: 1.62271 Total loss: 1.87275</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.79s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:280: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 2/100. Iteration: 16/16. Cls loss: 0.37282. Reg loss: 0.79529. Batch loss: 1.16810 Total loss: 1.34164</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.79s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 3/100. Iteration: 16/16. Cls loss: 0.28747. Reg loss: 0.60461. Batch loss: 0.89208 Total loss: 0.95898</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 4/100. Iteration: 16/16. Cls loss: 0.24303. Reg loss: 0.41299. Batch loss: 0.65602 Total loss: 0.82356</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 5/100. Iteration: 16/16. Cls loss: 0.16664. Reg loss: 0.44385. Batch loss: 0.61049 Total loss: 0.74072</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 6/100. Iteration: 16/16. Cls loss: 0.20120. Reg loss: 0.45322. Batch loss: 0.65442 Total loss: 0.69949</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 7/100. Iteration: 16/16. Cls loss: 0.17003. Reg loss: 0.40236. Batch loss: 0.57240 Total loss: 0.65084</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 8/100. Iteration: 16/16. Cls loss: 0.24190. Reg loss: 0.40061. Batch loss: 0.64250 Total loss: 0.62492</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 9/100. Iteration: 16/16. Cls loss: 0.22273. Reg loss: 0.48177. Batch loss: 0.70450 Total loss: 0.58830</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 10/100. Iteration: 16/16. Cls loss: 0.15339. Reg loss: 0.33673. Batch loss: 0.49012 Total loss: 0.56875</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:2578: UserWarning: Exporting aten::index operator with indices of type Byte. Only 1-D indices are supported. In any other case, this will produce an incorrect ONNX graph.\n",
            "  warnings.warn(\"Exporting aten::index operator with indices of type Byte. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:662: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
            "  \"intended to be used with dynamic input shapes, please use opset version 11 to export the model.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 11/100. Iteration: 16/16. Cls loss: 0.11737. Reg loss: 0.35666. Batch loss: 0.47404 Total loss: 0.52304</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 12/100. Iteration: 16/16. Cls loss: 0.13926. Reg loss: 0.34890. Batch loss: 0.48816 Total loss: 0.48913</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 13/100. Iteration: 16/16. Cls loss: 0.11964. Reg loss: 0.23020. Batch loss: 0.34983 Total loss: 0.47086</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 14/100. Iteration: 16/16. Cls loss: 0.13375. Reg loss: 0.27792. Batch loss: 0.41167 Total loss: 0.46266</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 15/100. Iteration: 16/16. Cls loss: 0.11726. Reg loss: 0.31100. Batch loss: 0.42826 Total loss: 0.45502</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 16/100. Iteration: 16/16. Cls loss: 0.08467. Reg loss: 0.24968. Batch loss: 0.33435 Total loss: 0.45738</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 17/100. Iteration: 16/16. Cls loss: 0.08235. Reg loss: 0.25440. Batch loss: 0.33675 Total loss: 0.39464</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:30&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 18/100. Iteration: 16/16. Cls loss: 0.10260. Reg loss: 0.22390. Batch loss: 0.32650 Total loss: 0.40143</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 19/100. Iteration: 16/16. Cls loss: 0.12174. Reg loss: 0.18262. Batch loss: 0.30436 Total loss: 0.37064</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 20/100. Iteration: 16/16. Cls loss: 0.05743. Reg loss: 0.19782. Batch loss: 0.25525 Total loss: 0.36059</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:30&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 21/100. Iteration: 16/16. Cls loss: 0.14527. Reg loss: 0.29892. Batch loss: 0.44419 Total loss: 0.37795</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 22/100. Iteration: 16/16. Cls loss: 0.10114. Reg loss: 0.28916. Batch loss: 0.39030 Total loss: 0.34493</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 23/100. Iteration: 16/16. Cls loss: 0.07869. Reg loss: 0.20544. Batch loss: 0.28413 Total loss: 0.35543</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 24/100. Iteration: 16/16. Cls loss: 0.07701. Reg loss: 0.28811. Batch loss: 0.36513 Total loss: 0.33179</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 25/100. Iteration: 16/16. Cls loss: 0.08799. Reg loss: 0.24662. Batch loss: 0.33461 Total loss: 0.32933</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 26/100. Iteration: 16/16. Cls loss: 0.08569. Reg loss: 0.25341. Batch loss: 0.33910 Total loss: 0.30125</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:30&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 27/100. Iteration: 16/16. Cls loss: 0.04684. Reg loss: 0.18193. Batch loss: 0.22877 Total loss: 0.29875</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.75s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 28/100. Iteration: 16/16. Cls loss: 0.07715. Reg loss: 0.20640. Batch loss: 0.28355 Total loss: 0.29001</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:30&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 29/100. Iteration: 16/16. Cls loss: 0.05828. Reg loss: 0.18673. Batch loss: 0.24501 Total loss: 0.27192</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 30/100. Iteration: 16/16. Cls loss: 0.07479. Reg loss: 0.21106. Batch loss: 0.28585 Total loss: 0.27780</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 31/100. Iteration: 16/16. Cls loss: 0.09657. Reg loss: 0.20156. Batch loss: 0.29813 Total loss: 0.25831</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 32/100. Iteration: 16/16. Cls loss: 0.06705. Reg loss: 0.18851. Batch loss: 0.25556 Total loss: 0.26051</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 33/100. Iteration: 16/16. Cls loss: 0.05890. Reg loss: 0.19672. Batch loss: 0.25562 Total loss: 0.26294</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 34/100. Iteration: 16/16. Cls loss: 0.05120. Reg loss: 0.18231. Batch loss: 0.23351 Total loss: 0.24537</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 35/100. Iteration: 16/16. Cls loss: 0.03766. Reg loss: 0.15302. Batch loss: 0.19068 Total loss: 0.23988</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 36/100. Iteration: 16/16. Cls loss: 0.02675. Reg loss: 0.13210. Batch loss: 0.15885 Total loss: 0.22807</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 37/100. Iteration: 16/16. Cls loss: 0.04371. Reg loss: 0.21647. Batch loss: 0.26018 Total loss: 0.24958</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 38/100. Iteration: 16/16. Cls loss: 0.05022. Reg loss: 0.15822. Batch loss: 0.20844 Total loss: 0.23283</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 39/100. Iteration: 16/16. Cls loss: 0.06206. Reg loss: 0.18899. Batch loss: 0.25105 Total loss: 0.20806</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.75s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 40/100. Iteration: 16/16. Cls loss: 0.03010. Reg loss: 0.12974. Batch loss: 0.15983 Total loss: 0.20706</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 41/100. Iteration: 16/16. Cls loss: 0.04648. Reg loss: 0.18832. Batch loss: 0.23480 Total loss: 0.20256</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 42/100. Iteration: 16/16. Cls loss: 0.04071. Reg loss: 0.16280. Batch loss: 0.20350 Total loss: 0.18431</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 43/100. Iteration: 16/16. Cls loss: 0.06217. Reg loss: 0.19204. Batch loss: 0.25421 Total loss: 0.18638</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 44/100. Iteration: 16/16. Cls loss: 0.02971. Reg loss: 0.14175. Batch loss: 0.17146 Total loss: 0.20240</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.75s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 45/100. Iteration: 16/16. Cls loss: 0.02752. Reg loss: 0.11507. Batch loss: 0.14259 Total loss: 0.18501</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 46/100. Iteration: 16/16. Cls loss: 0.11021. Reg loss: 0.12867. Batch loss: 0.23888 Total loss: 0.18176</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 47/100. Iteration: 16/16. Cls loss: 0.04355. Reg loss: 0.15842. Batch loss: 0.20197 Total loss: 0.19569</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 48/100. Iteration: 16/16. Cls loss: 0.04713. Reg loss: 0.11058. Batch loss: 0.15771 Total loss: 0.18299</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 49/100. Iteration: 16/16. Cls loss: 0.02116. Reg loss: 0.13186. Batch loss: 0.15302 Total loss: 0.16876</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 50/100. Iteration: 16/16. Cls loss: 0.02256. Reg loss: 0.11887. Batch loss: 0.14143 Total loss: 0.17836</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 51/100. Iteration: 16/16. Cls loss: 0.02541. Reg loss: 0.12694. Batch loss: 0.15235 Total loss: 0.18879</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 52/100. Iteration: 16/16. Cls loss: 0.02333. Reg loss: 0.14577. Batch loss: 0.16911 Total loss: 0.16201</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.80s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 53/100. Iteration: 16/16. Cls loss: 0.02189. Reg loss: 0.10117. Batch loss: 0.12306 Total loss: 0.15622</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 54/100. Iteration: 16/16. Cls loss: 0.01700. Reg loss: 0.10644. Batch loss: 0.12344 Total loss: 0.15958</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 55/100. Iteration: 16/16. Cls loss: 0.03805. Reg loss: 0.15646. Batch loss: 0.19450 Total loss: 0.16814</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 56/100. Iteration: 16/16. Cls loss: 0.02215. Reg loss: 0.12521. Batch loss: 0.14735 Total loss: 0.16038</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 57/100. Iteration: 16/16. Cls loss: 0.02525. Reg loss: 0.14457. Batch loss: 0.16982 Total loss: 0.16604</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch    57: reducing learning rate of group 0 to 1.0000e-05.\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 58/100. Iteration: 16/16. Cls loss: 0.01496. Reg loss: 0.07460. Batch loss: 0.08956 Total loss: 0.14069</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 59/100. Iteration: 16/16. Cls loss: 0.03029. Reg loss: 0.12247. Batch loss: 0.15276 Total loss: 0.12775</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 60/100. Iteration: 16/16. Cls loss: 0.02130. Reg loss: 0.09428. Batch loss: 0.11558 Total loss: 0.12518</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 61/100. Iteration: 16/16. Cls loss: 0.02153. Reg loss: 0.12766. Batch loss: 0.14919 Total loss: 0.12073</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 62/100. Iteration: 16/16. Cls loss: 0.02356. Reg loss: 0.09593. Batch loss: 0.11950 Total loss: 0.12576</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 63/100. Iteration: 16/16. Cls loss: 0.02192. Reg loss: 0.09545. Batch loss: 0.11737 Total loss: 0.12420</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 64/100. Iteration: 16/16. Cls loss: 0.02786. Reg loss: 0.11251. Batch loss: 0.14037 Total loss: 0.12401</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 65/100. Iteration: 16/16. Cls loss: 0.02452. Reg loss: 0.10772. Batch loss: 0.13224 Total loss: 0.11678</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 66/100. Iteration: 16/16. Cls loss: 0.01964. Reg loss: 0.10037. Batch loss: 0.12001 Total loss: 0.12148</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 67/100. Iteration: 16/16. Cls loss: 0.03075. Reg loss: 0.13058. Batch loss: 0.16133 Total loss: 0.12983</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 68/100. Iteration: 16/16. Cls loss: 0.02107. Reg loss: 0.09290. Batch loss: 0.11397 Total loss: 0.12601</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.75s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 69/100. Iteration: 16/16. Cls loss: 0.01330. Reg loss: 0.07528. Batch loss: 0.08858 Total loss: 0.12403</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:30&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch    69: reducing learning rate of group 0 to 1.0000e-06.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 70/100. Iteration: 16/16. Cls loss: 0.02064. Reg loss: 0.09760. Batch loss: 0.11824 Total loss: 0.11539</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 71/100. Iteration: 16/16. Cls loss: 0.02090. Reg loss: 0.09041. Batch loss: 0.11130 Total loss: 0.11725</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 72/100. Iteration: 16/16. Cls loss: 0.02679. Reg loss: 0.11200. Batch loss: 0.13879 Total loss: 0.11270</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.75s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 73/100. Iteration: 16/16. Cls loss: 0.02988. Reg loss: 0.13358. Batch loss: 0.16346 Total loss: 0.11956</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 74/100. Iteration: 16/16. Cls loss: 0.01958. Reg loss: 0.07323. Batch loss: 0.09281 Total loss: 0.11901</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 75/100. Iteration: 16/16. Cls loss: 0.02085. Reg loss: 0.04655. Batch loss: 0.06740 Total loss: 0.11181</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 76/100. Iteration: 16/16. Cls loss: 0.02231. Reg loss: 0.09130. Batch loss: 0.11361 Total loss: 0.10902</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 77/100. Iteration: 16/16. Cls loss: 0.02256. Reg loss: 0.10653. Batch loss: 0.12909 Total loss: 0.11703</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 78/100. Iteration: 16/16. Cls loss: 0.01060. Reg loss: 0.06038. Batch loss: 0.07098 Total loss: 0.10357</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 79/100. Iteration: 16/16. Cls loss: 0.01744. Reg loss: 0.07509. Batch loss: 0.09253 Total loss: 0.11991</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.75s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 80/100. Iteration: 16/16. Cls loss: 0.01437. Reg loss: 0.06374. Batch loss: 0.07811 Total loss: 0.11794</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 81/100. Iteration: 16/16. Cls loss: 0.02198. Reg loss: 0.10135. Batch loss: 0.12332 Total loss: 0.11995</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 82/100. Iteration: 16/16. Cls loss: 0.01746. Reg loss: 0.07649. Batch loss: 0.09395 Total loss: 0.11454</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch    82: reducing learning rate of group 0 to 1.0000e-07.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 83/100. Iteration: 16/16. Cls loss: 0.01654. Reg loss: 0.06994. Batch loss: 0.08648 Total loss: 0.12306</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 84/100. Iteration: 16/16. Cls loss: 0.02503. Reg loss: 0.09520. Batch loss: 0.12023 Total loss: 0.11622</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 85/100. Iteration: 16/16. Cls loss: 0.01784. Reg loss: 0.10700. Batch loss: 0.12484 Total loss: 0.10903</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 86/100. Iteration: 16/16. Cls loss: 0.01754. Reg loss: 0.08404. Batch loss: 0.10158 Total loss: 0.10817</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch    86: reducing learning rate of group 0 to 1.0000e-08.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 87/100. Iteration: 16/16. Cls loss: 0.02362. Reg loss: 0.07726. Batch loss: 0.10088 Total loss: 0.11793</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:30&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 88/100. Iteration: 16/16. Cls loss: 0.02940. Reg loss: 0.10003. Batch loss: 0.12943 Total loss: 0.12722</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.75s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 89/100. Iteration: 16/16. Cls loss: 0.01284. Reg loss: 0.05554. Batch loss: 0.06838 Total loss: 0.10990</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:30&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 90/100. Iteration: 16/16. Cls loss: 0.01641. Reg loss: 0.06259. Batch loss: 0.07900 Total loss: 0.11039</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 91/100. Iteration: 16/16. Cls loss: 0.02423. Reg loss: 0.08079. Batch loss: 0.10502 Total loss: 0.11035</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 92/100. Iteration: 16/16. Cls loss: 0.01370. Reg loss: 0.07126. Batch loss: 0.08496 Total loss: 0.10916</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 93/100. Iteration: 16/16. Cls loss: 0.04406. Reg loss: 0.13829. Batch loss: 0.18235 Total loss: 0.11001</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.75s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 94/100. Iteration: 16/16. Cls loss: 0.03633. Reg loss: 0.14385. Batch loss: 0.18017 Total loss: 0.12317</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 95/100. Iteration: 16/16. Cls loss: 0.03991. Reg loss: 0.12043. Batch loss: 0.16034 Total loss: 0.11462</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.75s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 96/100. Iteration: 16/16. Cls loss: 0.01867. Reg loss: 0.08776. Batch loss: 0.10644 Total loss: 0.11598</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "faild onnx export\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 97/100. Iteration: 16/16. Cls loss: 0.01263. Reg loss: 0.05439. Batch loss: 0.06701 Total loss: 0.10717</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:28&lt;00:00,  1.76s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 98/100. Iteration: 16/16. Cls loss: 0.03218. Reg loss: 0.11854. Batch loss: 0.15072 Total loss: 0.11647</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:30&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 99/100. Iteration: 16/16. Cls loss: 0.01843. Reg loss: 0.08976. Batch loss: 0.10818 Total loss: 0.10928</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.82s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 100/100. Iteration: 16/16. Cls loss: 0.02127. Reg loss: 0.10358. Batch loss: 0.12485 Total loss: 0.11588</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:29&lt;00:00,  1.81s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 1h 1min 20s, sys: 1min 42s, total: 1h 3min 2s\n",
            "Wall time: 1h 5min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS0pKdfd_Qjl"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_i_WH1V_s5F"
      },
      "source": [
        "COCO_CLASSES = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
        "                \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\",\n",
        "                \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
        "                \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\",\n",
        "                \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\",\n",
        "                \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
        "                \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\",\n",
        "                \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
        "                \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
        "                \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "\n",
        "colors = [(39, 129, 113), (164, 80, 133), (83, 122, 114), (99, 81, 172), (95, 56, 104), (37, 84, 86), (14, 89, 122),\n",
        "          (80, 7, 65), (10, 102, 25), (90, 185, 109), (106, 110, 132), (169, 158, 85), (188, 185, 26), (103, 1, 17),\n",
        "          (82, 144, 81), (92, 7, 184), (49, 81, 155), (179, 177, 69), (93, 187, 158), (13, 39, 73), (12, 50, 60),\n",
        "          (16, 179, 33), (112, 69, 165), (15, 139, 63), (33, 191, 159), (182, 173, 32), (34, 113, 133), (90, 135, 34),\n",
        "          (53, 34, 86), (141, 35, 190), (6, 171, 8), (118, 76, 112), (89, 60, 55), (15, 54, 88), (112, 75, 181),\n",
        "          (42, 147, 38), (138, 52, 63), (128, 65, 149), (106, 103, 24), (168, 33, 45), (28, 136, 135), (86, 91, 108),\n",
        "          (52, 11, 76), (142, 6, 189), (57, 81, 168), (55, 19, 148), (182, 101, 89), (44, 65, 179), (1, 33, 26),\n",
        "          (122, 164, 26), (70, 63, 134), (137, 106, 82), (120, 118, 52), (129, 74, 42), (182, 147, 112), (22, 157, 50),\n",
        "          (56, 50, 20), (2, 22, 177), (156, 100, 106), (21, 35, 42), (13, 8, 121), (142, 92, 28), (45, 118, 33),\n",
        "          (105, 118, 30), (7, 185, 124), (46, 34, 146), (105, 184, 169), (22, 18, 5), (147, 71, 73), (181, 64, 91),\n",
        "          (31, 39, 184), (164, 179, 33), (96, 50, 18), (95, 15, 106), (113, 68, 54), (136, 116, 112), (119, 139, 130),\n",
        "          (31, 139, 34), (66, 6, 127), (62, 39, 2), (49, 99, 180), (49, 119, 155), (153, 50, 183), (125, 38, 3),\n",
        "          (129, 87, 143), (49, 87, 40), (128, 62, 120), (73, 85, 148), (28, 144, 118), (29, 9, 24), (175, 45, 108),\n",
        "          (81, 175, 64), (178, 19, 157), (74, 188, 190), (18, 114, 2), (62, 128, 96), (21, 3, 150), (0, 6, 95),\n",
        "          (2, 20, 184), (122, 37, 185)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22M37JrN_XO4"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "import cv2\n",
        "import time as time\n",
        "\n",
        "class Infer():\n",
        "    def __init__(self, verbose=1):\n",
        "        self.system_dict = {};\n",
        "        self.system_dict[\"verbose\"] = verbose;\n",
        "        self.system_dict[\"local\"] = {};\n",
        "        self.system_dict[\"local\"][\"common_size\"] = 512;\n",
        "        self.system_dict[\"local\"][\"mean\"] = np.array([[[0.485, 0.456, 0.406]]])\n",
        "        self.system_dict[\"local\"][\"std\"] = np.array([[[0.229, 0.224, 0.225]]])\n",
        "\n",
        "    def Model(self, model_dir=\"drive/MyDrive/trained/\"):\n",
        "        self.system_dict[\"local\"][\"model\"] = torch.load(model_dir + \"/signatrix_efficientdet_coco.pth\").module\n",
        "        if torch.cuda.is_available():\n",
        "            self.system_dict[\"local\"][\"model\"] = self.system_dict[\"local\"][\"model\"].cuda();\n",
        "\n",
        "    def Predict(self, img_path, class_list, vis_threshold = 0.4,output_folder = 'Inference'):\n",
        "\n",
        "        if not os.path.exists(output_folder):\n",
        "            os.makedirs(output_folder)\n",
        "        \n",
        "        image_filename = os.path.basename(img_path)\n",
        "        img = cv2.imread(img_path);\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB);\n",
        "        image = img.astype(np.float32) / 255.;\n",
        "        image = (image.astype(np.float32) - self.system_dict[\"local\"][\"mean\"]) / self.system_dict[\"local\"][\"std\"]\n",
        "        height, width, _ = image.shape\n",
        "        if height > width:\n",
        "            scale = self.system_dict[\"local\"][\"common_size\"] / height\n",
        "            resized_height = self.system_dict[\"local\"][\"common_size\"]\n",
        "            resized_width = int(width * scale)\n",
        "        else:\n",
        "            scale = self.system_dict[\"local\"][\"common_size\"] / width\n",
        "            resized_height = int(height * scale)\n",
        "            resized_width = self.system_dict[\"local\"][\"common_size\"]\n",
        "\n",
        "        image = cv2.resize(image, (resized_width, resized_height))\n",
        "\n",
        "        new_image = np.zeros((self.system_dict[\"local\"][\"common_size\"], self.system_dict[\"local\"][\"common_size\"], 3))\n",
        "        new_image[0:resized_height, 0:resized_width] = image\n",
        "\n",
        "        img = torch.from_numpy(new_image)\n",
        "        \n",
        "        t0 = time.time()\n",
        "        with torch.no_grad():\n",
        "            if torch.cuda.is_available():\n",
        "                scores, labels, boxes = self.system_dict[\"local\"][\"model\"](img.cuda().permute(2, 0, 1).float().unsqueeze(dim=0))\n",
        "            else:\n",
        "                scores, labels, boxes = self.system_dict[\"local\"][\"model\"](img.permute(2, 0, 1).float().unsqueeze(dim=0))              \n",
        "            boxes /= scale;\n",
        "        duration = time.time() - t0\n",
        "        print('Done. (%.3fs)' % (time.time() - t0))\n",
        "\n",
        "\n",
        "        try:\n",
        "            if boxes.shape[0] > 0:\n",
        "                output_image = cv2.imread(img_path)\n",
        "\n",
        "                for box_id in range(boxes.shape[0]):\n",
        "                    pred_prob = float(scores[box_id])\n",
        "                    if pred_prob < vis_threshold:\n",
        "                        break\n",
        "                    pred_label = int(labels[box_id])\n",
        "                    xmin, ymin, xmax, ymax = boxes[box_id, :]\n",
        "                    color = colors[pred_label]\n",
        "                    cv2.rectangle(output_image, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "                    text_size = cv2.getTextSize(class_list[pred_label] + ' : %.2f' % pred_prob, cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
        "\n",
        "                    cv2.rectangle(output_image, (xmin, ymin), (xmin + text_size[0] + 3, ymin + text_size[1] + 4), color, -1)\n",
        "                    cv2.putText(\n",
        "                        output_image, class_list[pred_label] + ' : %.2f' % pred_prob,\n",
        "                        (xmin, ymin + text_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1,\n",
        "                        (255, 255, 255), 1)\n",
        "\n",
        "            #cv2.imwrite(os.path.join(output_folder, image_filename), output_image)\n",
        "            #cv2.imwrite(\"output.jpg\", output_image)\n",
        "            return duration, scores, labels, boxes\n",
        "        \n",
        "        except:\n",
        "            print(\"NO Object Detected\")\n",
        "            return None\n",
        "\n",
        "    def predict_batch_of_images(self, img_folder, class_list, vis_threshold = 0.4, output_folder='Inference'):\n",
        "        \n",
        "        all_filenames = os.listdir(img_folder)\n",
        "        all_filenames.sort()\n",
        "        generated_count = 0\n",
        "        for filename in all_filenames:\n",
        "            img_path = \"{}/{}\".format(img_folder, filename)\n",
        "            try:\n",
        "                self.Predict(img_path , class_list, vis_threshold ,output_folder)\n",
        "                generated_count += 1\n",
        "            except:\n",
        "                continue\n",
        "        print(\"Objects detected  for {} images\".format(generated_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL6ttyUMAH0x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "86b94d59-5101-418e-83cb-4aa6a507030f"
      },
      "source": [
        "gtf = Infer()\n",
        "gtf.Model(model_dir=\"drive/MyDrive/trained_weight/\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4ac2ce5f0222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"drive/MyDrive/trained_weight/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-c78dc3e08e7f>\u001b[0m in \u001b[0;36mModel\u001b[0;34m(self, model_dir)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"drive/MyDrive/trained/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/signatrix_efficientdet_coco.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'EfficientDet' on <module '__main__'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foy8ObZrANZ3",
        "outputId": "1e603940-cd9a-441d-f83c-16c60984d3cf"
      },
      "source": [
        "#extract class list from our annotations\n",
        "import json\n",
        "with open('space/train/_annotations.coco.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "class_list = []\n",
        "for category in data['categories']:\n",
        "  class_list.append(category['name'])\n",
        "\n",
        "class_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'Astroid', 'Space_craft']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "97mjPLMMANdP",
        "outputId": "60bf6c93-1f58-4067-995a-98ac5d3724de"
      },
      "source": [
        "test_images = [f for f in os.listdir('space/test') if f.endswith('.jpg')]\n",
        "import random\n",
        "img_path = \"space/test/\" + random.choice(test_images);\n",
        "#img_path = \"space/test/\" +\"trial.jpg\";\n",
        "\n",
        "#img_path=\"Downloads/trial.jpg\";\n",
        "duration, scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-888a48adfa29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'space/test'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"space/test/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#img_path = \"space/test/\" +\"trial.jpg\";\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk2-nJh1ZjNt"
      },
      "source": [
        "pred = {}\n",
        "pred['boxes'] = boxes\n",
        "pred['scores'] = scores\n",
        "pred['labels'] = labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiLEi4OVZRQ0"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "def apply_nms(orig_prediction, iou_thresh=0.3):\n",
        "    \n",
        "    # torchvision returns the indices of the bboxes to keep\n",
        "    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n",
        "    \n",
        "    final_prediction = orig_prediction\n",
        "    final_prediction['boxes'] = final_prediction['boxes'][keep]\n",
        "    final_prediction['scores'] = final_prediction['scores'][keep]\n",
        "    final_prediction['labels'] = final_prediction['labels'][keep]\n",
        "    \n",
        "    return final_prediction\n",
        "\n",
        "pred = apply_nms(pred, iou_thresh=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "gXjHVR7TYsAX",
        "outputId": "99a9d462-6128-431c-a43b-e2a683862e2c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "plt.rcParams['text.color'] = 'white'\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "fig, a = plt.subplots(1,1)\n",
        "fig.set_size_inches(5,5)\n",
        "a.imshow(img)\n",
        "for (box, label, score) in zip(pred['boxes'], pred['labels'], pred['scores']):\n",
        "    x, y, width, height  = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
        "    rect = patches.Rectangle((x, y),\n",
        "                                width, height,\n",
        "                                linewidth = 1,\n",
        "                                edgecolor = 'g',\n",
        "                                facecolor = 'none')\n",
        "\n",
        "    s = class_list[label.cpu().numpy()] + ' ({})'.format(score.item())\n",
        "    print(s)\n",
        "    a.text(x-5, y-5, s)\n",
        "\n",
        "    # Draw the bounding box on top of the image\n",
        "    a.add_patch(rect)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Space_craft (0.8616958260536194)\n",
            "Astroid (0.660862386226654)\n",
            "Astroid (0.646281361579895)\n",
            "Astroid (0.5755127668380737)\n",
            "Space_craft (0.06687666475772858)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WcrVN8FkEs4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}